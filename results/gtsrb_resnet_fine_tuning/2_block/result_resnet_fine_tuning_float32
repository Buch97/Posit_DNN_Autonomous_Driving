Float32 mode
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         [(None, 32, 32, 3)]       0
_________________________________________________________________
sequential_1 (Sequential)    (None, 32, 32, 3)         0
_________________________________________________________________
tf.math.truediv (TFOpLambda) (None, 32, 32, 3)         0
_________________________________________________________________
tf.math.subtract (TFOpLambda (None, 32, 32, 3)         0
_________________________________________________________________
resnet50v2 (Functional)      (None, 1, 1, 2048)        23564800
_________________________________________________________________
my_glo_avg_pool (GlobalAvera (None, 2048)              0
_________________________________________________________________
predictions (Dense)          (None, 43)                88107
=================================================================
Total params: 23,652,907
Trainable params: 9,005,099
Non-trainable params: 14,647,808
_________________________________________________________________
DATASET: gtsrb
WARNING:tensorflow:From /home/matteo/PycharmProjects/seai_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
2023-09-07 10:03:13.248712: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)
accuracy: 0.7370568732466207
123/123 [==============================] - 10s 70ms/step - loss: 0.7996 - accuracy: 0.7371
Test accuracy: 0.737, test loss: 0.800
Classification report:
              precision    recall  f1-score   support

           0     1.0000    0.8571    0.9231        21
           1     0.6786    0.7703    0.7215       222
           2     0.6157    0.7333    0.6694       225
           3     0.6970    0.3262    0.4444       141
           4     0.5979    0.5707    0.5840       198
           5     0.6503    0.5000    0.5653       186
           6     0.7674    0.7857    0.7765        42
           7     0.8725    0.6181    0.7236       144
           8     0.4758    0.4184    0.4453       141
           9     0.9339    0.7687    0.8433       147
          10     0.6220    0.7861    0.6945       201
          11     0.7951    0.7348    0.7638       132
          12     0.8879    0.9048    0.8962       210
          13     0.9550    0.9815    0.9680       216
          14     1.0000    0.8333    0.9091        78
          15     0.6914    0.8889    0.7778        63
          16     0.9111    0.9762    0.9425        42
          17     0.9322    0.9910    0.9607       111
          18     0.6992    0.7167    0.7078       120
          19     0.4571    0.7619    0.5714        21
          20     0.7778    0.3889    0.5185        36
          21     0.8261    0.5758    0.6786        33
          22     0.9200    0.5897    0.7188        39
          23     0.6111    0.6471    0.6286        51
          24     0.8000    0.4444    0.5714        27
          25     0.5145    0.8267    0.6343       150
          26     0.6522    0.5000    0.5660        60
          27     0.6923    0.3750    0.4865        24
          28     0.7143    0.5556    0.6250        54
          29     0.8235    0.5185    0.6364        27
          30     0.7576    0.5556    0.6410        45
          31     0.8642    0.8974    0.8805        78
          32     0.7917    0.7917    0.7917        24
          33     0.7368    0.8116    0.7724        69
          34     0.8837    0.9048    0.8941        42
          35     0.8720    0.9083    0.8898       120
          36     0.8387    0.6667    0.7429        39
          37     0.8571    0.8571    0.8571        21
          38     0.6879    0.9372    0.7935       207
          39     1.0000    0.9667    0.9831        30
          40     0.8710    0.7500    0.8060        36
          41     0.9167    0.9167    0.9167        24
          42     0.8182    0.7500    0.7826        24

    accuracy                         0.7371      3921
   macro avg     0.7783    0.7223    0.7373      3921
weighted avg     0.7489    0.7371    0.7322      3921