
Float32 mode
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         [(None, 32, 32, 3)]       0
_________________________________________________________________
tf.math.truediv (TFOpLambda) (None, 32, 32, 3)         0
_________________________________________________________________
tf.math.subtract (TFOpLambda (None, 32, 32, 3)         0
_________________________________________________________________
resnet50v2 (Functional)      (None, 1, 1, 2048)        23564800
_________________________________________________________________
my_glo_avg_pool (GlobalAvera (None, 2048)              0
_________________________________________________________________
predictions (Dense)          (None, 43)                88107
=================================================================
Total params: 23,652,907
Trainable params: 88,107
Non-trainable params: 23,564,800
_________________________________________________________________
DATASET: gtsrb
WARNING:tensorflow:From /home/matteo/PycharmProjects/seai_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
2023-09-12 12:40:16.885104: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)
<class 'numpy.float32'>
accuracy: 0.9273144605967866
123/123 [==============================] - 11s 78ms/step - loss: 0.2480 - accuracy: 0.9273
Test accuracy: 0.927, test loss: 0.248
Classification report:
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000        21
           1     0.8921    0.9685    0.9287       222
           2     0.9409    0.8489    0.8925       225
           3     0.9912    0.8014    0.8863       141
           4     0.7957    0.9444    0.8637       198
           5     0.9177    0.7796    0.8430       186
           6     0.9767    1.0000    0.9882        42
           7     0.9444    0.8264    0.8815       144
           8     0.7661    0.9291    0.8397       141
           9     0.9796    0.9796    0.9796       147
          10     0.9378    0.9751    0.9561       201
          11     0.9270    0.9621    0.9442       132
          12     0.9901    0.9524    0.9709       210
          13     0.9906    0.9769    0.9837       216
          14     1.0000    0.9487    0.9737        78
          15     1.0000    0.9841    0.9920        63
          16     1.0000    1.0000    1.0000        42
          17     0.9250    1.0000    0.9610       111
          18     0.9474    0.9000    0.9231       120
          19     0.9500    0.9048    0.9268        21
          20     1.0000    0.8889    0.9412        36
          21     0.9706    1.0000    0.9851        33
          22     0.8462    0.8462    0.8462        39
          23     0.9259    0.9804    0.9524        51
          24     0.9615    0.9259    0.9434        27
          25     0.8758    0.8933    0.8845       150
          26     0.8358    0.9333    0.8819        60
          27     0.8519    0.9583    0.9020        24
          28     0.8596    0.9074    0.8829        54
          29     0.7500    0.8889    0.8136        27
          30     0.9348    0.9556    0.9451        45
          31     0.9692    0.8077    0.8811        78
          32     1.0000    1.0000    1.0000        24
          33     0.9710    0.9710    0.9710        69
          34     0.9535    0.9762    0.9647        42
          35     0.9752    0.9833    0.9793       120
          36     0.9730    0.9231    0.9474        39
          37     0.9524    0.9524    0.9524        21
          38     0.9401    0.9855    0.9623       207
          39     1.0000    0.9333    0.9655        30
          40     0.9444    0.9444    0.9444        36
          41     1.0000    0.8333    0.9091        24
          42     1.0000    0.8750    0.9333        24

    accuracy                         0.9273      3921
   macro avg     0.9387    0.9313    0.9331      3921
weighted avg     0.9317    0.9273    0.9273      3921