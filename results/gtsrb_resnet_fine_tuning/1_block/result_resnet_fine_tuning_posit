Posit mode
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         [(None, 32, 32, 3)]       0
_________________________________________________________________
sequential_1 (Sequential)    (None, 32, 32, 3)         0
_________________________________________________________________
tf.math.truediv (TFOpLambda) (None, 32, 32, 3)         0
_________________________________________________________________
tf.math.subtract (TFOpLambda (None, 32, 32, 3)         0
_________________________________________________________________
resnet50v2 (Functional)      (None, 1, 1, 2048)        23564800
_________________________________________________________________
my_glo_avg_pool (GlobalAvera (None, 2048)              0
_________________________________________________________________
predictions (Dense)          (None, 43)                88107
=================================================================
Total params: 23,652,907
Trainable params: 4,546,603
Non-trainable params: 19,106,304
_________________________________________________________________
DATASET: gtsrb
WARNING:tensorflow:From /home/matteo/PycharmProjects/seai_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
2023-09-07 09:57:29.545816: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)
accuracy: 0.6449885233358837
123/123 [==============================] - 9s 60ms/step - loss: 1.0890 - accuracy: 0.6450
Test accuracy: 0.645, test loss: 1.089
Classification report:
              precision    recall  f1-score   support

           0     0.4545    0.2381    0.3125        21
           1     0.5305    0.5090    0.5195       222
           2     0.6256    0.6089    0.6171       225
           3     0.5825    0.4255    0.4918       141
           4     0.4847    0.4798    0.4822       198
           5     0.3711    0.6344    0.4683       186
           6     0.8085    0.9048    0.8539        42
           7     0.5380    0.6875    0.6037       144
           8     0.5111    0.1631    0.2473       141
           9     0.7985    0.7279    0.7616       147
          10     0.5563    0.8358    0.6680       201
          11     0.6915    0.4924    0.5752       132
          12     0.9016    0.8286    0.8635       210
          13     0.9710    0.9306    0.9504       216
          14     0.9211    0.8974    0.9091        78
          15     0.8205    0.5079    0.6275        63
          16     0.9474    0.8571    0.9000        42
          17     0.9244    0.9910    0.9565       111
          18     0.5510    0.6750    0.6067       120
          19     0.3333    0.0952    0.1481        21
          20     0.7000    0.1944    0.3043        36
          21     0.5789    0.3333    0.4231        33
          22     0.3494    0.7436    0.4754        39
          23     0.5250    0.4118    0.4615        51
          24     0.6667    0.2222    0.3333        27
          25     0.5689    0.6333    0.5994       150
          26     0.3678    0.5333    0.4354        60
          27     0.4545    0.2083    0.2857        24
          28     0.6500    0.2407    0.3514        54
          29     0.7333    0.4074    0.5238        27
          30     0.5098    0.5778    0.5417        45
          31     0.4412    0.9615    0.6048        78
          32     0.7500    0.7500    0.7500        24
          33     0.9400    0.6812    0.7899        69
          34     0.8276    0.5714    0.6761        42
          35     0.9259    0.8333    0.8772       120
          36     0.9167    0.5641    0.6984        39
          37     0.7308    0.9048    0.8085        21
          38     0.8508    0.7440    0.7938       207
          39     1.0000    0.7333    0.8462        30
          40     0.7931    0.6389    0.7077        36
          41     0.6207    0.7500    0.6792        24
          42     0.6538    0.7083    0.6800        24

    accuracy                         0.6450      3921
   macro avg     0.6716    0.6009    0.6095      3921
weighted avg     0.6722    0.6450    0.6404      3921


Process finished with exit code 0