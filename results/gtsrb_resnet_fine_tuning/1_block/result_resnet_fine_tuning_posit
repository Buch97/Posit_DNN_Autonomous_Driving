Posit mode
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
tf.math.truediv_1 (TFOpLambd (None, 32, 32, 3)         0         
_________________________________________________________________
tf.math.subtract_1 (TFOpLamb (None, 32, 32, 3)         0         
_________________________________________________________________
resnet50v2 (Functional)      (None, 1, 1, 2048)        23564800  
_________________________________________________________________
my_glo_avg_pool (GlobalAvera (None, 2048)              0         
_________________________________________________________________
predictions (Dense)          (None, 43)                88107     
=================================================================
Total params: 23,652,907
Trainable params: 4,546,603
Non-trainable params: 19,106,304
_________________________________________________________________
DATASET: gtsrb
WARNING:tensorflow:From /home/matteo/PycharmProjects/seai_project/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
2023-09-21 11:05:50.501163: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:164] None of the MLIR Optimization Passes are enabled (registered 2)
<class 'posit160'>
accuracy: 0.897985207855139
123/123 [==============================] - 3364s 27s/step - loss: 0.3240 - accuracy: 0.8980
Test accuracy: 0.898, test loss: 0.324
Classification report: 
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000        21
           1     0.8730    0.9595    0.9142       222
           2     0.9514    0.7822    0.8585       225
           3     0.9266    0.7163    0.8080       141
           4     0.5913    0.9646    0.7332       198
           5     0.9209    0.6882    0.7877       186
           6     0.9756    0.9524    0.9639        42
           7     0.9813    0.7292    0.8367       144
           8     0.8041    0.8440    0.8235       141
           9     0.9533    0.9728    0.9630       147
          10     0.9091    0.9453    0.9268       201
          11     0.9118    0.9394    0.9254       132
          12     0.9902    0.9619    0.9758       210
          13     0.9952    0.9537    0.9740       216
          14     1.0000    0.9487    0.9737        78
          15     1.0000    0.9841    0.9920        63
          16     1.0000    0.9286    0.9630        42
          17     0.9402    0.9910    0.9649       111
          18     0.9211    0.8750    0.8974       120
          19     0.9500    0.9048    0.9268        21
          20     0.8824    0.8333    0.8571        36
          21     0.9375    0.9091    0.9231        33
          22     0.7619    0.8205    0.7901        39
          23     0.9091    0.9804    0.9434        51
          24     0.8929    0.9259    0.9091        27
          25     0.8323    0.8933    0.8617       150
          26     0.8154    0.8833    0.8480        60
          27     0.9200    0.9583    0.9388        24
          28     0.7812    0.9259    0.8475        54
          29     0.8000    0.8889    0.8421        27
          30     0.9524    0.8889    0.9195        45
          31     0.9828    0.7308    0.8382        78
          32     1.0000    1.0000    1.0000        24
          33     0.9552    0.9275    0.9412        69
          34     1.0000    0.9286    0.9630        42
          35     0.9748    0.9667    0.9707       120
          36     0.9211    0.8974    0.9091        39
          37     0.9500    0.9048    0.9268        21
          38     0.9273    0.9855    0.9555       207
          39     1.0000    0.8667    0.9286        30
          40     0.8947    0.9444    0.9189        36
          41     1.0000    0.8750    0.9333        24
          42     0.9583    0.9583    0.9583        24

    accuracy                         0.8980      3921
   macro avg     0.9220    0.9055    0.9101      3921
weighted avg     0.9119    0.8980    0.8992      3921